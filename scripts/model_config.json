{
  "description": "Model training configuration for temporal splits",
  "comment": "Define train/validation/test/OOT periods to prevent data leakage and simulate production deployment",
  "date_convention": "BOTH start_date and end_date are INCLUSIVE [start_date, end_date]. Example: train 2023-01-01 to 2023-08-01 includes BOTH Jan 1 and Aug 1 snapshots.",

  "temporal_window_mode": "absolute",
  "mode_description": "Use 'absolute' for fixed dates (initial training) or 'relative' for dynamic rolling windows (retraining)",

  "relative_windows": {
    "description": "Dynamic temporal windows calculated from snapshot_date - PRODUCTION MODE",
    "train": {
      "months_back": 12,
      "description": "Use last 12 months of data before snapshot for training"
    },
    "validation": {
      "months_after_train_end": 3,
      "description": "3 months after training period ends"
    },
    "test": {
      "months_after_validation_end": 2,
      "description": "2 months after validation period ends"
    },
    "oot": {
      "months_after_test_end": 1,
      "description": "1 month after test period ends - simulates production deployment"
    }
  },

  "temporal_splits": {
    "description": "Absolute date mode - Used when temporal_window_mode='absolute' or as fallback",
    "train": {
      "start_date": "2023-01-01",
      "end_date": "2023-12-01",
      "description": "Training period - earliest data for model learning"
    },
    "validation": {
      "start_date": "2024-01-01",
      "end_date": "2024-02-01",
      "description": "Validation period - hyperparameter tuning and model selection"
    },
    "test": {
      "start_date": "2024-03-01",
      "end_date": "2024-04-01",
      "description": "Test period - final evaluation before deployment"
    },
    "oot": {
      "start_date": "2024-05-01",
      "end_date": "2024-05-01",
      "description": "Out-of-Time period - production simulation with completely unseen future data"
    }
  },

  "model_selection": {
    "primary_metric": "val_roc_auc",
    "secondary_metric": "val_accuracy",
    "minimum_samples": 100,
    "description": "Criteria for selecting best model"
  },

  "training_params": {
    "model_1": {
      "model_type": "logistic_regression",
      "max_iter": 1000,
      "C": 1.0,
      "class_weight": "balanced",
      "random_state": 42
    },
    "model_2": {
      "model_type": "gradient_boosting",
      "n_estimators": 100,
      "learning_rate": 0.05,
      "max_depth": 3,
      "min_samples_split": 50,
      "min_samples_leaf": 20,
      "subsample": 0.8,
      "random_state": 42
    }
  }
}
